---
title: Mining Causal Signal Temporal Logic Formulas for Efficient Reinforcement Learning
  with Temporally Extended Tasks
abstract: Reinforcement Learning (RL) has emerged as a powerful paradigm for solving
  sequential decision-making problems. However, traditional RL methods often lack
  an understanding of the causal mechanisms that govern the dynamics of an environment.
  This limitation results in inefficiencies, challenges in generalization, and reduced
  interpretability. To address these challenges, we propose Signal Temporal Logic
  Causal Inference RL (STL-CIRL), a framework that mines interpretable causal specifications
  through Signal Temporal Logic and reinforcement learning, using counterexample-guided
  refinement to jointly optimize policies and causal formulas. We compare the performance
  of agents leveraging explicit causal knowledge with those relying solely on traditional
  RL approaches. Our results demonstrate the potential of causal reasoning to enhance
  the efficiency and robustness of RL for complex tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: partovi-aria25a
month: 0
tex_title: Mining Causal Signal Temporal Logic Formulas for Efficient Reinforcement
  Learning with Temporally Extended Tasks
firstpage: 524
lastpage: 542
page: 524-542
order: 524
cycles: false
bibtex_author: Partovi Aria, Hadi and Xu, Zhe
author:
- given: Hadi
  family: Partovi Aria
- given: Zhe
  family: Xu
date: 2025-07-08
address:
container-title: Proceedings of the International Conference on Neuro-symbolic Systems
volume: '288'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v288/main/assets/partovi-aria25a/partovi-aria25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
