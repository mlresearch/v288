@Proceedings{NeuS,
  booktitle    = {Proceedings of the International Conference on Neuro-symbolic Systems},
  name         = {International Conference on Neuro-symbolic Systems},
  shortname    = {NeuS},
  year         = {2025},
  editor       = {Pappas, George and Ravikumar, Pradeep and Seshia, Sanjit A.},
  volume       = {288},
  start        = {2025-05-28},
  end          = {2025-05-30},
  address      = {University of Pennsylvania, Philadelphia, Pennsylvania, USA},
  conference_url    = {https://neus-2025.github.io/},
  conference_number = {2}
}

@InProceedings{geng25,
  title    = {Learning Minimal Neural Specifications},
  author   = {Geng, Chuqin and Wang, Zhaoyue and Ye, Haolin and Si, Xujie},
  pages    = {1--21},
  abstract = {Formal verification is only as good as the specification of a system, which is also true for neural network verification. Existing specifications follow the paradigm of data as specification, where the local neighborhood around a reference data point is considered correct or robust. While these specifications provide a fair testbed for assessing model robustness, they are too restrictive for verifying any unseen test data points---a challenging task with significant real-world implications. Recent work shows great promise through a new paradigm, neural representation as specification, which uses neural activation patterns (NAPs) for this purpose. However, it computes the most refined NAPs, which include many redundant neurons. In this paper, we study the following problem: Given a neural network, find a minimal (general) NAP specification that is sufficient for formal verification of its robustness properties. Finding the minimal NAP specification not only expands verifiable bounds but also provides insights into which set of neurons contributes to the model's robustness. To address this problem, we propose three approaches: conservative, statistical, and optimistic. Each of these methods offers distinct strengths and trade-offs in terms of minimality and computational speed, making them suitable for scenarios with different priorities. Notably, the optimistic approach can probe potential causal links between neurons and the robustness of large vision neural networks without relying on verification tools---a task existing methods struggle to scale. Our experiments show that minimal NAP specifications use far fewer neurons than those from previous work while expanding verifiable boundaries by several orders of magnitude.},
}

@InProceedings{goetting25,
  title    = {End-to-End Navigation with Vision-Language Models: Transforming Spatial Reasoning into Question-Answering},
  author   = {Goetting, Dylan and Singh, Himanshu Gaurav and Loquercio, Antonio},
  pages    = {22--35},
  abstract = {We present VLMnav, an embodied framework to transform a Vision-Language Model (VLM) into an end-to-end navigation policy. In contrast to prior work, we do not rely on a separation between perception, planning, and control; instead, we use a VLM to directly select actions in one step. Surprisingly, we find that a VLM can be used as an end-to-end policy zero-shot, i.e., without any fine-tuning or exposure to navigation data. This makes our approach open-ended and generalizable to any downstream navigation task. We run an extensive study to evaluate the performance of our approach in comparison to baseline prompting methods. In addition, we perform a design analysis to understand the most impactful design decisions. Visual examples and code for our project can be found at jirl-upenn.github.io/VLMnav/.},
}

@InProceedings{wang25a,
  title    = {Why Neural Networks Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning},
  author   = {Wang, Peihao and Wang, Zhangyang ``Atlas''},
  pages    = {36--65},
  abstract = {We develop a theoretical framework that explains how discrete symbolic structures can emerge naturally from continuous neural network training dynamics. By lifting neural parameters to a measure space and modeling training as Wasserstein gradient flow, we show that under geometric constraints, such as group invariance, the parameter measure $\mu_t$ undergoes two concurrent phenomena: (1) a decoupling of the gradient flow into independent optimization trajectories over some potential functions, and (2) a progressive contraction on the degree of freedom. These potentials encode algebraic constraints relevant to the task and act as ring homomorphisms under a commutative semi-ring structure on the measure space. As training progresses, the network transitions from a high-dimensional exploration to compositional representations that comply with algebraic operations and exhibit a lower degree of freedom. We further establish data scaling laws for realizing symbolic tasks, linking representational capacity to the group invariance that facilitates symbolic solutions. This framework charts a principled foundation for understanding and designing neurosymbolic systems that integrate continuous learning with discrete algebraic reasoning},
}

@InProceedings{peper25,
  title    = {Four Principles for Physically Interpretable World Models},
  author   = {Peper, Jordan and Mao, Zhenjiang and Geng, Yuang and Pan, Siyuan and Ruchkin, Ivan},
  pages    = {66--89},
  abstract = {As autonomous systems are increasingly deployed in open and uncertain settings, there is a growing need for trustworthy neuro-symbolic world models that can reliably predict future high-dimensional observations. The learned latent representations in world models lack direct mapping to meaningful physical quantities and dynamics, limiting their utility and interpretability in downstream planning, control, and safety verification. In this paper, we argue for a fundamental shift from physically informed to physically interpretable world models---and crystallize four principles that leverage symbolic knowledge to achieve these ends: (1) functionally organizing the latent space according to the physical intent, (2) learning aligned invariant and equivariant representations of the physical world, (3) integrating multiple forms and strengths of supervision into a unified training process, and (4) partitioning generative outputs to support scalability and verifiability. We experimentally demonstrate the value of each principle on two benchmarks. This paper opens several intriguing research directions to achieve and capitalize on full physical interpretability in learned world models.},
}

@InProceedings{kresse25,
  title    = {Logic Gate Neural Networks are Good for Verification},
  author   = {Kresse, Fabian and Yu, Emily and Lampert, Christoph H. and Henzinger, Thomas A.},
  pages    = {90--103},
  abstract = {Learning-based systems are increasingly deployed across various domains, yet the complexity of traditional neural networks poses significant challenges for formal verification. Unlike conventional neural networks, learned Logic Gate Networks (LGNs) replace multiplications with Boolean logic gates, yielding a sparse, netlist-like architecture that is inherently more amenable to symbolic verification, while still delivering promising performance. In this paper, we introduce a SAT encoding for verifying global robustness and fairness in LGNs. We evaluate our method on five benchmark datasets, including a newly constructed 5-class variant, and find that LGNs are both verification-friendly and maintain strong predictive performance.},
}

@InProceedings{potteiger25,
  title    = {Real-Time Reachability for Neurosymbolic Reinforcement Learning-based Safe Autonomous Navigation},
  author   = {Potteiger, Nicholas and Manzanas Lopez, Diego and Johnson, Taylor T. and Koutsoukos, Xenofon},
  pages    = {104--126},
  abstract = {Safety is essential in autonomous navigation, especially as autonomous systems deploy to new environments where collision avoidance is critical. Neurosymbolic reinforcement learning (NeSy RL) approaches show promise for advancing long-term navigation by using symbolic planners to compute high-level waypoints and goal-conditioned RL for low-level control. However, ensuring safety within these frameworks remains a challenge, particularly in new environments that the agent was not optimized for. Current safe RL-based navigation techniques offer robust frameworks for ensuring safety. However, these approaches are not adapted for NeSy RL and also present challenges: they can be computationally intensive or constrained by conservative control. To overcome these limitations, we propose a novel approach to safely and efficiently navigate a NeSy RL agent in new environments. The proposed method uses real-time reachability analysis to select subgoals between waypoints and safeguard the actions of a goal-conditioned RL policy. We implement the approach in Rust and develop a software package, RusTReach, for real-time reachability analysis. We deploy our approach on an embedded device and compare against four approaches in a long-term quadcopter navigation task in a new environment. Our evaluation reveals that our approach is at least 1.7 times faster at navigating than a state-of-the-art alternative while maintaining safety and real-time constraint compliance. Code and videos available at https://github.com/npotteig/rustreach.},
}

@InProceedings{waite25,
  title    = {State-Dependent Conformal Perception Bounds for Neuro-Symbolic Verification of Autonomous Systems},
  author   = {Waite, Thomas and Geng, Yuang and Turnquist, Trevor and Ruchkin, Ivan and Ivanov, Radoslav},
  pages    = {127--143},
  abstract = {It remains a challenge to provide safety guarantees for autonomous systems with neural perception and control. A typical approach obtains symbolic bounds on perception error (e.g., using conformal prediction) and performs verification under these bounds. However, these bounds can lead to drastic conservatism in the resulting end-to-end safety guarantee. This paper proposes an approach to synthesize symbolic perception error bounds that serve as an optimal interface between perception performance and control verification. The key idea is to consider our error bounds to be heteroskedastic with respect to the system’s state — not time like in previous approaches. These bounds can be obtained with two gradient-free optimization algorithms. We demonstrate that our bounds lead to tighter safety guarantees than the state-of-the-art in a case study on a mountain car.},
}

@InProceedings{song25,
  title    = {Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean},
  author   = {Song, Peiyang and Yang, Kaiyu and Anandkumar, Anima},
  pages    = {144--169},
  abstract = {Neural theorem proving combines large language models (LLMs) with proof assistants such as Lean, where the correctness of formal proofs can be rigorously verified, leaving no room for hallucination. With existing neural theorem provers pretrained on a fixed collection of data and offering valuable suggestions at times, it is challenging for them to continually prove novel theorems in a fully autonomous mode, where human insights may be critical. In this paper, we explore LLMs as copilots that assist humans in proving theorems. We introduce Lean Copilot, a general framework for running LLM inference natively in Lean. It enables programmers to build various LLM-based proof automation tools that integrate seamlessly into the workflow of Lean users. Lean users can use our pretrained models or bring their own ones that run either locally (with or without GPUs) or on the cloud. Using Lean Copilot, we build LLM-based tools that suggest proof steps, complete proof goals, and select relevant premises. Experimental results on the Mathematics in Lean textbook demonstrate the effectiveness of our method compared to existing rule-based proof automation in Lean (AESOP), confirming the significance of having LLMs integrated into the theorem proving workflow in Lean. When assisting humans, Lean Copilot requires only 2.08 manually-entered proof steps on average (3.86 required by AESOP); when automating the theorem proving process, Lean Copilot automates 74.2% proof steps on average, 85% better than AESOP (40.1%). We open source all code and artifacts under a permissive MIT license to facilitate further research.},
}

@InProceedings{sasaki25,
  title    = {Neurosymbolic Finite and Pushdown Automata: Improved Multimodal Reasoning versus Vision Language Models (VLMs)},
  author   = {Sasaki, Samuel and Manzanas Lopez, Diego and Johnson, Taylor T.},
  pages    = {170--187},
  abstract = {Multimodal large language models (LLMs), such as vision language models (VLMs), are powerful reasoning tools that have been shown to be capable of solving non-trivial tasks such as image and video reasoning, translation, and text generation. Alternatively, LLMs have also regularly been shown to have difficulties with trivial tasks like performing elementary mathematical reasoning problems and arithmetic. Significant effort has since gone towards directly addressing these tasks in order to show reasoning in LLMs. Despite an extensive training regimen that includes state-of-the-art hardware support and copious amounts of data, it is still straightforward to modify a, now, relatively trivial task such that the LLM again experiences a great deal of difficulty in solving the task. In this work, we focus on two tasks, image-based string acceptance and image-based arithmetic evaluation, for VLMs to solve that involve non-trivial multimodal reasoning and introduce a new neurosymbolic-based model of computation that can significantly outperform VLMs on them. We define two classes of neurosymbolic automata to address this problem, namely neurosymbolic finite automata (NSFA) and neurosymbolic pushdown automata (NSPDA). These neurosymbolic automata are able to model the image-based string acceptance and arithmetic evaluation tasks well, given their derivation from finite and pushdown automata for string acceptance and arithmetic evaluation. We show that state-of-the-art LLMs with multimodal reasoning capabilities are not only outperformed by neurosymbolic automata, but often fail to reason about the tasks altogether with the VLMs getting zero correct in the arithmetic evaluation task while the NSPDA demonstrates 88% accuracy with 2 operands and a steady decline as the complexity of the expressions increased, as expected.},
}

@InProceedings{christopher25,
  title    = {Neuro-Symbolic Generative Diffusion Models for Physically Grounded, Robust, and Safe Generation},
  author   = {Christopher, Jacob K. and Cardei, Michael and Liang, Jinhao and Fioretto, Ferdinando},
  pages    = {188--213},
  abstract = {Despite the remarkable generative capabilities of diffusion models, their integration into safety-critical or scientifically rigorous applications remains hindered by the need to ensure compliance with stringent physical, structural, and operational constraints. To address this challenge, this paper introduces Neuro-Symbolic Diffusion (NSD), a novel framework that interleaves diffusion steps with symbolic optimization, enabling the generation of certifiably consistent samples under user-defined functional and logic constraints. This key feature is provided for both standard and discrete diffusion models, enabling, for the first time, the generation of both continuous (e.g., images and trajectories) and discrete (e.g., molecular structures and natural language) outputs that comply with constraints. This ability is demonstrated on tasks spanning three key challenges: (1) Safety, in the context of non-toxic molecular generation and collision-free trajectory optimization; (2) Data scarcity, in domains such as drug discovery and materials engineering; and (3) Out-of-domain generalization, where enforcing symbolic constraints allows adaptation beyond the training distribution.},
}

@InProceedings{yu25,
  title    = {Learning Subject to Constraints via Abstract Gradient Descent},
  author   = {Yu, Shiwen and Liu, Wanwei and Liu, Zengyu and Chen, Liqian and Wang, Ting and Zhan, Naijun and Wang, Ji},
  pages    = {214--230},
  abstract = {Deep learning has made significant advancements and has been successfully used in different areas. However, current deep learning models are based on theories of probability and statistics, thus suffer from adhering to constraints and ensuring assurances. In contrast, symbolic methods inherently own rigidity but with low efficiency and high cost. In this paper, we propose a novel symbolic learning architecture which can deal with data fitting and logic satisfaction uniformly. The key idea is to treat logic formulas as discrete functions that can be optimized through Abstract Gradient Descent, a discrete optimization method based on backward abstract interpretation. The efficiency of our approach is illustrated by training a symbolic neural network with 8,542 parameters that can accurately recognize 70,000 handwritten digits. Experiments indicate that the trained model not only fits the data well but also adheres to key properties such as robustness, invariance to zooming, translation, resistance to noise background, and so on.},
}

@InProceedings{huang25,
  title    = {Differentiable Synthesis of Behavior Tree Architectures and Execution Nodes},
  author   = {Huang, Yu and Wu, Ziji and Ma, Kexin and Wang, Ji},
  pages    = {231--259},
  abstract = {Deep reinforcement learning (DRL) has achieved remarkable success in solving complex control tasks. However, neural network policies often lack interpretability and struggle to generalize to new scenarios without further training. Behavior trees (BTs) offer a more interpretable policy representation, making them a promising alternative. Yet, the automatic synthesis of BTs remains a challenge due to the discrete search space and the need to adapt to diverse scenarios. Prior works often come at the cost of fixed or constrained architectures, or rely on customized execution nodes. We propose an end-to-end synthesis framework that simultaneously generates the architectures and execution nodes of BTs solely from environment rewards. We first conduct architecture search on top of a continuous relaxation of the architecture search space derived from a given grammar. To tackle the discrete execution mechanism and non-differentiable semantics of BTs, we redefine the execution mechanism and interpret the semantics in terms of a differentiable approximation. We also propose an efficient extraction algorithm that leverages the fallback structure of BTs to instantiate a valid BT architecture. This algorithm recovers the performance damaged by the co-adaptation and continuous approximation. Experimental results show the superior performance and generalization of our synthesized BTs, demonstrating the efficacy of the proposed framework.},
}

@InProceedings{kim25,
  title    = {Knowledge-Enriched Machine Learning for Tabular Data},
  author   = {Kim, Juyong and Squires, Chandler and Ravikumar, Pradeep},
  pages    = {260--292},
  abstract = {In this paper, we introduce the general framework of knowledge-enriched machine learning for encoding and leveraging problem-specific deterministic knowledge, such as column descriptions in the tabular setting. We focus on supervised learning problems on tabular data and present a flexible encoding of such deterministic information in the form of concept kernels. We describe meta-algorithms which leverage this encoding and introduce KE-TALENT, a benchmarking suite adapted from TALENT to include concept kernels and metadata for each dataset. Experimental results on kernel-enriched versions of existing algorithms demonstrate improved performance, establishing baselines and grounding future research. Code is publicly available.},
}

@InProceedings{pirozelli25,
  title    = {A Study of Modus Ponens in Transformer Models},
  author   = {Pirozelli, Paulo and Cozman, Fabio G.},
  pages    = {293--315},
  abstract = {Transformer models are the backbone of modern natural language processing. However, whether they can truly perform logical reasoning remains uncertain. This paper examines transformers' capacity for logical inference in a controlled setting, isolating a single rule---modus ponens---and eliminating confounding factors such as semantic knowledge and linguistic complexity. We systematically vary architectural components, specifically the number of attention heads and layers, to assess their impact on logical inference. Our results show that attention heads enhance information propagation, whereas deeper architectures accelerate convergence but also introduce potentially redundant parameters. While transformers successfully handle level-2 inference tasks, their difficulties with higher-level and out-of-distribution problems suggest that they rely on heuristic ``shortcuts'' rather than explicit multi-step reasoning. Analysis of attention maps and ablation experiments indicates that these shortcuts function similarly to a matching-aggregation algorithm, where attention heads identify inference links, and the feed-forward network verifies if they form a valid chain. These findings highlight fundamental limitations in transformers' ability to perform structured logical reasoning.},
}

@InProceedings{jothimurugan25,
  title    = {Specification-Guided Reinforcement Learning},
  author   = {Jothimurugan, Kishor and Bansal, Suguman and Bastani, Osbert and Alur, Rajeev},
  pages    = {316--330},
  abstract = {This tutorial explores specification-guided reinforcement learning as an alternative to traditional reward-based approaches, where the design of effective reward functions can be tedious, error-prone, and may not capture complex objectives. We introduce formal logical specifications as a more intuitive and precise way to define agent behavior, focusing on the theoretical guarantees and algorithmic aspects of learning from specifications. We examine both fundamental limitations in infinite-horizon settings and practical approaches for finite-horizon specifications.},
}

@InProceedings{leung25,
  title    = {From Road to Code: Neuro-Symbolic Program Synthesis for Autonomous Driving Scene Translation and Analysis},
  author   = {Leung, Johnathan and Tong, Guansen and Duggirala, Parasara Sridhar and Chakravarthula, Praneeth},
  pages    = {331--351},
  abstract = {Translating real-world scenarios into simulation environments is essential for the safe, cost-effective, and scalable development of autonomous vehicles. Simulations enable rigorous testing of complex, rare, and hazardous scenarios, while also allowing for rapid iteration, data generation, and exposure to diverse conditions. However, the real-to-sim gap remains a significant challenge, as automated methods often fail to accurately capture real-world conditions, and manual scenario generation is labor-intensive and struggles to replicate realistic dynamics and unpredictable human behavior. In this work, we propose Road2Code, a framework that bridges the gap between real-world traffic data and simulation by leveraging neuro-symbolic program synthesis. Road2Code translates real-world driving scenarios into Scenic programs for the CARLA simulator, utilizing large language models for code generation. To enhance efficiency, we employ a distillation approach, where a large language teacher model generates reasoning processes that refine training for a smaller student model used for inference. Road2Code enhances simulation fidelity by accurately modeling real-world scenarios and agent behaviors, while enabling scenario editing and counterfactual analysis, providing essential tools for testing and refining autonomous vehicle behavior. This direct link between real-world data and simulation lays a foundation for advancing trustworthy and transparent autonomous driving research, accelerating progress toward reliable autonomous vehicle systems.},
}

@InProceedings{debauche25,
  title    = {Formal Synthesis of Lyapunov Stability Certificates for Linear Switched Systems using ReLU Neural Networks},
  author   = {Debauche, Virginie and Edwards, Alec and Jungers, Raphael M. and Abate, Alessandro},
  pages    = {352--364},
  abstract = {This paper presents a neural network-based algorithm with soundness guarantees to study the stability of discrete-time linear switched systems. This algorithm follows a counterexample guided inductive synthesis (CEGIS) architecture: an iterative process alternating between the learner, which provides a candidate Lyapunov function, and the verifier which checks its validity over the whole domain. We choose a ReLU neural network as learner for its expressivity and flexibility, and a satisfiability module theories (SMT) solver as verifier. In addition, we introduce a post processing step to leverage a valid Lyapunov function from the neural network in case of failure of the CEGIS loop. Several examples demonstrate the algorithm's efficacy.},
}

@InProceedings{shah25a,
  title    = {Learning Formal Specifications from Membership and Preference Queries},
  author   = {Shah, Ameesh and Vazquez-Chanlatte, Marcell and Junges, Sebastian and Seshia, Sanjit A.},
  pages    = {365--383},
  abstract = {Active learning is a well-studied approach to learning formal specifications, such as automata. In this work, we extend active specification learning by proposing a novel framework that strategically requests a combination of membership labels and pair-wise preferences, a popular alternative to membership labels. We formalize the notion of using preference queries in the context of specification learning by introducing Membership Respecting Preferences (MemRePs), a class of pair-wise preferences that can be used in conjunction with membership queries. The combination of pair-wise preferences and membership labels allows for a more flexible approach to active specification learning, often reducing the number of membership queries required to learn specifications. We instantiate our framework for two different classes of specifications, demonstrating the generality of our approach. Our results suggest that learning from both modalities allows us to robustly and conveniently identify specifications via membership and preferences.},
}

@InProceedings{molom25,
  title    = {Efficient Neuro-Symbolic Policy using In-Memory Computing},
  author   = {Molom-Ochir, Tergel and Saxena, Naman and Kim, Jiwoo and Chen, Yiran and Wang, Zhangyang and Pajic, Miroslav and Li, Hai ``Helen''},
  pages    = {384--395},
  abstract = {As artificial intelligence (AI) systems grow in complexity, achieving computationally efficient and interpretable decision-making is crucial. Neuro-Symbolic AI (NeSy) offers a promising framework by integrating symbolic representation with neural learning, but its execution on traditional hardware remains inefficient due to memory bottlenecks and high computational costs. This paper advocates for a paradigm shift in AI acceleration---moving beyond traditional von Neumann architectures toward memory-centric computation, unlocking real-time, scalable, and interpretable decision-making for next-generation AI applications. We envision a future where In-Memory Computing (IMC)-based acceleration fundamentally transforms Neuro-Symbolic policy acceleration by mapping it onto hardware-associative memory, enabling O(1) complexity decision-making with drastically reduced energy consumption and latency. Our preliminary results show that IMC-based symbolic policies achieve up to 100x speedup and six orders of magnitude better energy efficiency than CPU and GPU implementations. Moreover, we discuss how probabilistic symbolic policies can be realized within IMC architectures, enabling AI systems to handle uncertainty while maintaining efficiency.},
}

@InProceedings{bortolussi25,
  title    = {Neuro-Symbolic Discovery of Markov Population Processes},
  author   = {Bortolussi, Luca and Cairoli, Francesca and Klein, Julia and Petrov, Tatjana},
  pages    = {396--408},
  abstract = {Markov population processes (MPPs) are the natural modeling choice in various application domains where multiple interacting entities evolve stochastically over time, including biology, queueing theory, finance, and robotics. Motivated by real-world scenarios where time-series data for MPP models is increasingly available, we here employ a neuro-symbolic approach for discovering explanations of such data in terms of local, agent-to-agent interactions. Concretely, we assume that equidistant time-series measurements of a Markov population chain are given. Then, we propose how to automatically learn the explanatory models written in form of Chemical Reaction Networks (CRNs). Our approach is to use a symbolic representation of a CRN in form of a weighted bipartite graph, and to employ a graph-based Variational Autoencoder (VAE) to jointly infer both the interactions and the accompanying kinetic parameters. We demonstrate our proposed framework over three simple case studies. Our contribution represents a proof-of-concept that interpretable models of complex dynamical systems can be discovered in a fully automated and data-driven fashion, and it is applicable both in scenarios where data is available via experiments, or when it is generated by a black-box simulator.},
}

@InProceedings{serbinowska25,
  title    = {Neuro-Symbolic Behavior Trees (NSBTs) and Their Verification},
  author   = {Serbinowska, Serena S. and Manzanas Lopez, Diego and Nguyen, Dung Thuy and Johnson, Taylor T.},
  pages    = {409--423},
  abstract = {Neural networks have proven to be incredibly powerful and useful in a variety of domains, but are also often opaque and difficult to reason about. This is undesirable in safety-critical systems. An approach to help mitigate this is to utilize a neuro-symbolic approach that combines the power of neural networks and symbolic structures. In this paper, we present Neuro-Symbolic Behavior Trees (NSBTs). NSBTs are behavior trees that utilize neural networks. We provide several examples of NSBTs, including grid-world examples and a representation of a portion of ACAS Xu, an aircraft collision avoidance system. The grid world example considers over 6 million input states for the neural network, while the ACAS Xu example features 5 networks, each with 6 layers of 50 neurons. Additionally, we implemented support for NSBTs in our BehaVerify software tool, and verify certain safety and liveness properties for these NSBTs. Our verification approach also demonstrates how future improvements could be made using existing neural network verification techniques.},
}

@InProceedings{chen25,
  title    = {KGAccel: A Domain-Specific Reconfigurable Accelerator for Knowledge Graph Reasoning},
  author   = {Chen, Hanning and Zakeri, Ali and Ni, Yang and Wen, Fei and Khaleghi, Behnam and Latapie, Hugo and Velasquez, Alvaro and Imani, Mohsen},
  pages    = {424--445},
  abstract = {Recent hardware accelerators for graph learning have largely overlooked knowledge graph reasoning (KGR), which demands more complex models and longer training times than typical graph tasks. Existing approaches rely on single or distributed GPUs to accelerate translational embedding models, but these general-purpose solutions lag in handling reinforcement learning-based KGR. To address this gap, we introduce KGAccel, the first domain-specific accelerator for RL-based KGR on FPGA. We develop a knowledge-graph compression method and propose a resource-aware mechanism that enables high-speed training even on smaller FPGAs. KGAccel achieves up to 65x speedup over CPU, 8x over GPU, and over 30x higher energy efficiency.},
}

@InProceedings{munoz25,
  title    = {ChatHTN: Interleaving Approximate (LLM) and Symbolic HTN Planning},
  author   = {Mu\~noz-Avila, H\'ector and Aha, David W. and Rizzo, Paola},
  pages    = {446--458},
  abstract = {We introduce ChatHTN, a Hierarchical Task Network (HTN) planner that combines symbolic HTN planning techniques with queries to ChatGPT to approximate solutions in the form of task decompositions. The resulting hierarchies interleave task decompositions generated by symbolic HTN planning with those generated by ChatGPT. Despite the approximate nature of the results generated by ChatGPT, ChatHTN is provably sound; any plan it generates correctly achieves the input tasks. We demonstrate this property with an open-source implementation of our system.},
}

@InProceedings{wang25b,
  title    = {Taxonomic Networks: A Representation for Neuro-Symbolic Pairing},
  author   = {Wang, Zekun and Haarer, Ethan L. and Barari, Nicki and MacLellan, Christopher J.},
  pages    = {459--471},
  abstract = {We introduce the concept of a neuro-symbolic pair---neural and symbolic approaches that are linked through a common knowledge representation. Next, we present taxonomic networks, a type of discrimination network in which nodes represent hierarchically organized taxonomic concepts. Using this representation, we construct a novel neuro-symbolic pair and evaluate its performance. We show that our symbolic method learns taxonomic nets more efficiently with less data and compute, while the neural method finds higher-accuracy taxonomic nets when provided with greater resources. As a neuro-symbolic pair, these approaches can be used interchangeably based on situational needs, with seamless translation between them when necessary. This work lays the foundation for future systems that more fundamentally integrate neural and symbolic computation.},
}

@InProceedings{liu25a,
  title    = {Interpretable Imitation Learning via Generative Adversarial STL Inference and Control},
  author   = {Liu, Wenliang and Li, Danyang and Aasi, Erfan and Rus, Daniela and Tron, Roberto and Belta, Calin},
  pages    = {472--489},
  abstract = {Imitation learning methods have demonstrated considerable success in teaching autonomous systems complex tasks through expert demonstrations. However, a limitation of these methods is their lack of interpretability, particularly in understanding the specific task the learning agent aims to accomplish. In this paper, we propose a novel imitation learning method that combines Signal Temporal Logic (STL) inference and control synthesis, enabling the explicit representation of the task as an STL formula. This approach not only provides a clear understanding of the task but also supports the integration of human knowledge and allows for adaptation to out-of-distribution scenarios by manually adjusting the STL formulas and fine-tuning the policy. We employ a Generative Adversarial Network (GAN)-inspired approach to train both the inference and policy networks, effectively narrowing the gap between expert and learned policies. The efficiency of our algorithm is demonstrated through simulations, showcasing its practical applicability and adaptability.},
}

@InProceedings{wan25,
  title    = {Efficient Processing of Neuro-Symbolic AI: A Tutorial and Cross-Layer Co-Design Case Study},
  author   = {Wan, Zishen and Liu, Che-Kai and Yang, Hanchen and Raj, Ritik and Raychowdhury, Arijit and Krishna, Tushar},
  pages    = {490--504},
  abstract = {While neural-based models have driven recent breakthroughs in artificial intelligence (AI), they face critical challenges in unsustainable computational demands, limited robustness, and lack of interpretability. Neuro-symbolic (NeSy) AI has emerged as a promising paradigm that integrates neural learning and symbolic reasoning to enhance explainability, robustness, and data efficiency. Recent NeSy systems demonstrated strong potential in reasoning and trustworthy decision-making tasks, making them particularly suitable for cognitive human-AI applications. This tutorial presents a vertically integrated approach on the efficient processing of NeSy AI, bridging workload characteristics with system and hardware co-design. We begin by systematically categorizing NeSy workloads and analyzing their computational and memory demands to expose performance bottlenecks and optimization opportunities. Building on these insights, we focus on a class of vector-symbolic architecture-based NeSy systems and present a series of hardware case studies, including processing element microarchitecture, dataflow, FPGA design, and system-on-chip prototype. Our results highlight the efficiency and scalability improvements of NeSy systems, with the integration of application discovery, systems thinking, and co-design intelligence. Project Website: https://effi-nesy.github.io.},
}

@InProceedings{hallyburton25,
  title    = {Assured Autonomy with Neuro-Symbolic Perception},
  author   = {Hallyburton, R. Spencer and Pajic, Miroslav},
  pages    = {505--523},
  abstract = {Many state-of-the-art AI models deployed in cyber-physical systems (CPS), while highly accurate, are simply pattern-matchers. With limited security guarantees, there are concerns for their reliability in safety-critical and contested domains. To advance assured AI, we advocate for a paradigm shift that imbues data-driven perception models with symbolic structure, inspired by a human’s ability to reason over low-level features and high-level context. We propose a neuro-symbolic paradigm for perception (NeuSPaPer) and illustrate how joint object detection and scene graph generation (SGG) yields deep scene understanding. Powered by foundation models for offline knowledge extraction and specialized SGG algorithms for real-time deployment, we design a framework leveraging structured relational graphs that ensures the integrity of situational awareness in autonomy. Using physics-based simulators and real-world datasets, we demonstrate how SGG bridges the gap between low-level sensor perception and high-level reasoning, establishing a foundation for resilient, context-aware AI and advancing trusted autonomy in CPS.},
}

@InProceedings{partovi25,
  title    = {Mining Causal Signal Temporal Logic Formulas for Efficient Reinforcement Learning with Temporally Extended Tasks},
  author   = {Partovi Aria, Hadi and Xu, Zhe},
  pages    = {524--542},
  abstract = {Reinforcement Learning (RL) has emerged as a powerful paradigm for solving sequential decision-making problems. However, traditional RL methods often lack an understanding of the causal mechanisms that govern the dynamics of an environment. This limitation results in inefficiencies, challenges in generalization, and reduced interpretability. To address these challenges, we propose Signal Temporal Logic Causal Inference RL (STL-CIRL), a framework that mines interpretable causal specifications through Signal Temporal Logic and reinforcement learning, using counterexample-guided refinement to jointly optimize policies and causal formulas. We compare the performance of agents leveraging explicit causal knowledge with those relying solely on traditional RL approaches. Our results demonstrate the potential of causal reasoning to enhance the efficiency and robustness of RL for complex tasks.},
}

@InProceedings{vazquez25,
  title    = {L*LM: Learning Automata from Demonstrations, Examples, and Natural Language},
  author   = {Vazquez-Chanlatte, Marcell and Elmaaroufi, Karim and Witwicki, Stefan and Zaharia, Matei and Seshia, Sanjit A.},
  pages    = {543--569},
  abstract = {Expert demonstrations have proven to be an easy way to indirectly specify complex tasks. Recent algorithms even support extracting unambiguous formal specifications, e.g. deterministic finite automata (DFA), from demonstrations. Unfortunately, these techniques are typically not sample-efficient. In this work, we introduce L*LM, an algorithm for learning DFAs from both demonstrations and natural language. Due to the expressivity of natural language, we observe a significant improvement in the data efficiency of learning DFAs from expert demonstrations. Technically, L*LM leverages large language models to answer membership queries about the underlying task. This is then combined with recent techniques for transforming learning from demonstrations into a sequence of labeled example learning problems. In our experiments, we observe the two modalities complement each other, yielding a powerful few-shot learner.},
}

@InProceedings{nunez25,
  title    = {Expansion Span: Combining Fading Memory and Retrieval in Hybrid State Space Models},
  author   = {Nunez, Elvis and Zancato, Luca and Bowman, Benjamin and Golatkar, Aditya and Xia, Wei and Soatto, Stefano},
  pages    = {570--596},
  abstract = {The ``state'' of State Space Models (SSMs) represents their memory, which fades exponentially over an unbounded span. By contrast, Attention-based models have ``eidetic'' (i.e., verbatim, or photographic) memory over a finite span (context size). Hybrid architectures combine State Space layers with Attention, but still cannot recall the distant past and can access only the most recent tokens eidetically. Unlike current methods of combining SSM and Attention layers, we allow the state to be allocated based on relevancy rather than recency. In this way, for every new set of query tokens, our models can ``eidetically'' access tokens from beyond the Attention span of current Hybrid SSMs without requiring extra hardware resources. We introduce a method to expand the memory span of the hybrid state by ``reserving'' a fraction of the Attention context for tokens retrieved from arbitrarily distant in the past, thus expanding the eidetic memory span of the overall state. We call this reserved fraction of tokens the ``expansion span,'' and the mechanism to retrieve and aggregate it ``Span-Expanded Attention'' (SE-Attn). To adapt Hybrid models to using SE-Attn, we propose a novel fine-tuning method that extends LoRA to Hybrid models (HyLoRA) and allows efficient adaptation on long spans of tokens. We show that SE-Attn enables us to efficiently adapt pre-trained Hybrid models on sequences of tokens up to 8 times longer than the ones used for pre-training. We show that HyLoRA with SE-Attn is cheaper and more performant than alternatives like LongLoRA when applied to Hybrid models on natural language benchmarks with long-range dependencies, such as PG-19, RULER, and other common natural language downstream tasks.},
}

@InProceedings{nadali25,
  title    = {Stochastic Neural Simulation Relations for Control Transfer},
  author   = {Nadali, Alireza and Trivedi, Ashutosh and Zamani, Majid},
  pages    = {597--620},
  abstract = {This paper explores a neurosymbolic approach to probabilistic transfer of control logic from a source stochastic control system to a target system while ensuring approximately equivalent behavioral guarantees in both domains. Traditional methods struggle with this problem due to the absence of a complete characterization of behavioral specifications, which prevents a direct formulation in terms of loss functions. To address this challenge, we leverage the concept of stochastic simulation relations to establish probabilistic observational equivalence between the behaviors of two (black-box) stochastic systems. These functions ensure that the outputs of both systems, equipped with their respective controllers, remain probabilistically close over time. By parameterizing stochastic simulation functions with neural networks, we introduce the notion of stochastic neural simulation functions, enabling a data-driven mechanism to transfer any synthesized controller—along with its proof of correctness—without requiring explicit specification of behavioral constraints. This neurosymbolic integration combines the scalability of neural methods with the formal guarantees of symbolic approaches, bridging the gap between learning-based control synthesis and formal verification. Compared to prior methods, our approach eliminates the need for a closed-loop mathematical model and explicit requirement specifications for both the source and target systems, while providing probabilistic guarantees over an infinite horizon. We also introduce validity conditions that, when satisfied, ensure the closeness of the outputs of two systems equipped with their corresponding controllers, removing the need for post-facto verification. We demonstrate the effectiveness of our approach through four case studies, highlighting its potential to advance scalable, formally grounded, and transferable control synthesis.},
}

@InProceedings{nagesh25,
  title    = {Taylor-Model Physics-Informed Neural Networks (PINNs) for Ordinary Differential Equations},
  author   = {Nagesh, Chandra Kanth and Sankaranarayanan, Sriram and Kaur, Ramneet and Sahai, Tuhin and Jha, Susmit},
  pages    = {621--642},
  abstract = {We study the problem of learning neural network models for Ordinary Differential Equations (ODEs) with parametric uncertainties. Such neural network models capture the solution to the ODE over a given set of parameters, initial conditions, and range of times. Physics-Informed Neural Networks (PINNs) have emerged as a promising approach for learning such models that combine data-driven deep learning with symbolic physics models in a principled manner. However, the accuracy of PINNs degrade when they are used to solve an entire family of initial value problems characterized by varying parameters and initial conditions. In this paper, we combine symbolic differentiation and Taylor series methods to propose a class of higher-order models for capturing the solutions to ODEs. These models combine neural networks and symbolic terms: they use higher order Lie derivatives and a Taylor series expansion obtained symbolically, with the remainder term modeled as a neural network. The key insight is that the remainder term can itself be modeled as a solution to a first-order ODE. We show how the use of these higher order PINNs can improve accuracy using interesting, but challenging ODE benchmarks. We also show that the resulting model can be quite useful for situations such as controlling uncertain physical systems modeled as ODEs.},
}

@InProceedings{alinejad25,
  title    = {Bidirectional End-to-End Framework for Transfer from Abstract Models in Non-Markovian Reinforcement Learning},
  author   = {Alinejad, Mahyar and Nwaorgu, Precious and Enyioha, Chinwendu and Wang, Yue and Velasquez, Alvaro and Atia, George},
  pages    = {643--660},
  abstract = {We propose a bidirectional end-to-end reinforcement learning (RL) framework for solving complex non-Markovian tasks in discrete and continuous environments. Instead of directly learning policies in high-dimensional spaces, we first construct a simplified teacher model as a surrogate environment from offline trajectories. Simultaneously, we infer a Deterministic Finite Automaton (DFA) using the RPNI algorithm to capture task dependencies. A policy is learned in the surrogate environment and transferred to the original domain via automaton distillation, which guides policy learning more effectively than direct RL in the original environment. Our framework integrates DQN for discrete tasks and DDPG/TD3 for continuous settings. Empirical results demonstrate that this structured transfer significantly improves learning efficiency and convergence speed, outperforming standard RL baselines.},
}

@InProceedings{yalcinkaya25,
  title    = {Provably Correct Automata Embeddings for Optimal Automata-Conditioned Reinforcement Learning},
  author   = {Yalcinkaya, Beyazit and Lauffer, Niklas and Vazquez-Chanlatte, Marcell and Seshia, Sanjit A.},
  pages    = {661--675},
  abstract = {Automata-conditioned reinforcement learning (RL) has given promising results for learning multi-task policies capable of performing temporally extended objectives given at runtime, done by pretraining and freezing automata embeddings prior to training the downstream policy. However, no theoretical guarantees were given. This work provides a theoretical framework for the automata-conditioned RL problem and shows that it is probably approximately correct (PAC) learnable. We then present a technique for learning provably correct automata embeddings, guaranteeing optimal multi-task policy learning. Our experimental evaluation confirms these theoretical results.},
}

@InProceedings{shah25b,
  title    = {A Challenge to Build Neuro-Symbolic Video Agents},
  author   = {Shah, Sahil and Goel, Harsh and Narasimhan, Sai Shankar and Choi, Minkyu and Sharan, S P and Akcin, Oguzhan and Chinchali, Sandeep},
  pages    = {676--692},
  abstract = {Modern video understanding systems excel at tasks such as scene classification, object detection, and short video retrieval. However, as video analysis becomes increasingly central to real-world applications, there is a growing need for proactive video agents—systems that not only interpret video streams but also reason about events and take informed actions. A key obstacle in this direction is temporal reasoning: while deep learning models have made remarkable progress in recognizing patterns within individual frames or short clips, they struggle to understand the sequencing and dependencies of events over time, which is critical for action-driven decision-making. Addressing this limitation demands moving beyond conventional deep learning approaches. We posit that tackling this challenge requires a neuro-symbolic perspective, where video queries are decomposed into atomic events, structured into coherent sequences, and validated against temporal constraints. Such an approach can enhance interpretability, enable structured reasoning, and provide stronger guarantees on system behavior, all key properties for advancing trustworthy video agents. To this end, we present a grand challenge to the research community: developing the next generation of intelligent video agents that integrate three core capabilities—(1) autonomous video search and analysis, (2) seamless real-world interaction, and (3) advanced content generation. By addressing these pillars, we can transition from passive perception to intelligent video agents that reason, predict, and act, pushing the boundaries of video understanding.},
}

@InProceedings{hashemi25,
  title    = {PCA-DDReach: Efficient Statistical Reachability Analysis of Stochastic Dynamical Systems via Principal Component Analysis},
  author   = {Hashemi, Navid and Lindemann, Lars and Deshmukh, Jyotirmoy V.},
  pages    = {693--707},
  abstract = {This paper proposes a scalable data-driven algorithm for reachability analysis of complex cyber-physical systems (CPS) without requiring parametric models. Traditional methods rely on known physical dynamics, which are often unavailable due to system complexity or variability. Instead, we treat such systems as black boxes and use trajectory data to learn predictive models. To quantify prediction uncertainty and ensure safety, we integrate conformal inference (CI) — a statistical tool for probabilistic guarantees — with Principal Component Analysis (PCA) to reduce conservatism and enhance scalability. Our method constructs probabilistic reachable sets that are less conservative under distribution shifts compared to prior CI-based methods. We validate the approach on high-dimensional systems, including a 12D quadcopter and a 27D powertrain model, demonstrating improved accuracy and computational efficiency over existing techniques.},
}

@InProceedings{canesse25,
  title    = {A Tutorial on Neural Network-Based Solvers for Hyperbolic Conservation Laws: Supervised vs. Unsupervised Learning, and Applications to Traffic Modeling},
  author   = {Canesse, Alexi and Fu, Zhe and Lichtlé, Nathan and Zinat Matin, Hossein Nick and Liu, Zihe and Delle Monache, Maria Laura and Bayen, Alexandre M.},
  pages    = {708--720},
  abstract = {Neural networks (NNs) are powerful tools for solving complex partial differential equations (PDEs) with high accuracy. However, many NN-based solvers are designed as general-purpose models or lack theoretical grounding, limiting their ability to capture essential solution properties such as regularity, conservation, and entropy conditions. This issue is especially critical for hyperbolic conservation laws, which govern wave propagation and shock formation, and are among the most challenging PDEs to solve accurately. This tutorial examines both supervised and unsupervised NN-based solvers from computational and theoretical perspectives, with a focus on NN-based finite volume methods (FVMs) tailored to conservation laws. In the supervised setting, NN solvers learn from available solution data, such as Riemann problems, to capture characteristic solution structures, while the unsupervised approach employs a weak formulation loss to enforce the correct weak solution behavior. In practice, both the supervised and unsupervised variants tend to learn the entropic solution, effectively handling discontinuities and shocks, and outperforming comparable numerical schemes in accuracy. This tutorial aims to provide a deeper understanding of NN-based solvers for PDEs and to present structure-preserving neural methods for scientific computing.},
}

@InProceedings{caulfield25,
  title    = {Modularity in Query-Based Concept Learning},
  author   = {Caulfield, Benjamin and Seshia, Sanjit A.},
  pages    = {721--744},
  abstract = {We define and study the problem of modular concept learning, which is learning a concept that is a cross-product (i.e., Cartesian product) of component concepts. The theory of concept learning provides a framework for analyzing algorithms for inductive synthesis of programs and systems, which involves synthesis from examples and queries. Modular concept learning is important for systems that can be broken into subsystems that each act independently of the other. We analyze this problem with respect to different types of queries that are made to an oracle, formalized as an oracle interface. We show that if a given oracle interface cannot directly answer questions about the components, learning can be difficult, even when the components are easy to learn with the same type of oracle queries. Specifically, we show that learning from membership, equivalence, or subset queries is hard. However, these problems become tractable when oracles are given a positive example and are allowed to ask membership queries.},
}

@InProceedings{liu25b,
  title    = {Observability of Latent States in Generative AI Models},
  author   = {Liu, Tian Yu and Soatto, Stefano and Marchi, Matteo and Chaudhari, Pratik and Tabuada, Paulo},
  pages    = {745--764},
  abstract = {We tackle the question of whether Large Language Models (LLMs), viewed as dynamical systems with state evolving in the embedding space of symbolic tokens, are observable. That is, whether there exist distinct state trajectories that yield the same sequence of generated output tokens, or sequences that belong to the same Nerode equivalence class (`meaning'). If an LLM is not observable, the state trajectory cannot be determined from input-output observations and can therefore evolve unbeknownst to the user while being potentially accessible to an adversary. We show that current LLMs implemented by autoregressive Transformers are observable: The set of state trajectories that produce the same tokenized output is a singleton, so there are no indistinguishable state trajectories. But if there are `system prompts' not visible to the user, then the set of indistinguishable trajectories becomes non-trivial, meaning that there can be multiple state trajectories that yield the same tokenized output. We prove these claims analytically, and show examples of modifications to standard LLMs that engender unobservable behavior. Our analysis sheds light on possible designs that would enable a model to perform non-trivial computation that is not visible to the user, and may suggest controls that can be implemented to prevent unintended behavior. Finally, we cast the definition of `feeling' from cognitive psychology in terms of measurable quantities in an LLM which, unlike humans, are directly measurable. We conclude that, in LLMs, unobservable state trajectories satisfy the definition of `feelings' provided by the American Psychological Association, suitably modified to avoid self-reference.},
}

@InProceedings{yang25,
  title    = {Automaton-Based Representations of Task Knowledge from Generative Language Models},
  author   = {Yang, Yunhao and Neary, Cyrus and Topcu, Ufuk},
  pages    = {765--783},
  abstract = {Automaton-based representations play an important role in control and planning for sequential decision-making problems. However, obtaining the high-level task knowledge required to build such automata is often difficult. Meanwhile, generated language models (GLMs) can automatically generate relevant text-based task knowledge. However, such text-based knowledge cannot be formally verified or used for sequential decision-making. We propose a novel algorithm named GLM2FSA that constructs a finite state automaton (FSA) encoding high-level task knowledge from a brief natural-language description of the task goal. GLM2FSA first sends queries to a GLM to extract task knowledge in textual form, and then it builds an FSA to represent this text-based knowledge. The proposed algorithm thus fills the gap between natural-language task descriptions and automaton-based representations, and the constructed FSAs can be formally verified against user-defined specifications. We accordingly propose a procedure to iteratively refine the input queries to the GLM based on the outcomes, e.g., counter-examples, from verification. We apply the proposed algorithm to an autonomous driving system to demonstrate its capability for sequential decision-making and formal verification. Furthermore, quantitative results indicate the refinement method improves the probability of generated knowledge satisfying the specifications by 40 percent.},
}